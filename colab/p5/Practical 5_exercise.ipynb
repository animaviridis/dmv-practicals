{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tHnOfjCJWcik"
   },
   "source": [
    "Data Mining and Visualisation 2019-2020 <br>\n",
    "Practical 5 - Time-Series Analysis and Processing - focus on Time-Series Classification<br>\n",
    "Teaching Assistant Muhammad Usman <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "49b77NelWvTL"
   },
   "source": [
    "This practical requires you to use time series classification approaches to classify multivariate sensor data based on whether the telecommunications network is actually up and running or not. -1 is the negative class denoting downtime and 1 is for optimal network condition. <br>\n",
    "Use this notebook with CoLab. <br>\n",
    "You may enable GPU capabilities <br>\n",
    "\n",
    "You need to undergo a number of steps to fill the gaps below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UpYz5AOoVDnb"
   },
   "outputs": [],
   "source": [
    "# Load all necessary libaries, including keras and tensorflow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sK06tuQlZTXk"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.upload() #upload the files needed with this command if you'd like. There are about 20 csv files and one for the target labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s8PGEvTcZVp3"
   },
   "outputs": [],
   "source": [
    "#Read one of the files and printi out with name.head(). Also try to return its shape with name.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O2rDJpjxb7vh"
   },
   "outputs": [],
   "source": [
    "#Now you need to provide the path where all the files can be found and start the import phase, e.g.\n",
    "path = '/content/Wireless_Telecom_' #Change the accordingly\n",
    "sequences = list()\n",
    "for i in range(#define range#):\n",
    "    file_path = path + str(i) + '.csv'\n",
    "    print(file_path)\n",
    "    df = pd.read_csv(file_path, header=0)\n",
    "    values = df.values\n",
    "    sequences.append(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QuDC4aJccWeE"
   },
   "outputs": [],
   "source": [
    "targets = #read the path that target file can be found\n",
    "targets = targets.values[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zZnlcHwdc5wa"
   },
   "outputs": [],
   "source": [
    "#sequences have different lengths. So we need to make that uniform based on some statistics. You need to provide some statistics with regards to the each sequence lengths, i.e. some sequences are longer than others.\n",
    "# use .describe() to get an idea of what the spread of the sequence lengths is\n",
    "len_sequences = []\n",
    "for one_seq in sequences:\n",
    "    len_sequences.append(len(one_seq))\n",
    "pd.Series(len_sequences).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SpdNC2vzkzaX"
   },
   "outputs": [],
   "source": [
    "#return for each sequence it length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qvYVhCCak3TB"
   },
   "outputs": [],
   "source": [
    "#add padding to the max length based on the value you got from .describe()\n",
    "to_pad = #####\n",
    "new_seq = []\n",
    "for one_seq in sequences:\n",
    "    len_one_seq = len(one_seq)\n",
    "    last_val = one_seq[-1]\n",
    "    n = to_pad - len_one_seq\n",
    "    to_concat = np.repeat(one_seq[-1], n).reshape(4, n).transpose()\n",
    "    new_one_seq = np.concatenate([one_seq, to_concat])\n",
    "    new_seq.append(new_one_seq)\n",
    "current_seq = np.stack(new_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C5JGBV2xlHyz"
   },
   "outputs": [],
   "source": [
    "#truncate the sequences to having 24 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G65lx3mrlOl1"
   },
   "outputs": [],
   "source": [
    "#now create train and test sets..... for the sake of this example we will consider the test set as being both a test and validation set, but you can just adjust it accordingly if you want to create a validation set as well\n",
    "train = [current_seq[i] for i in range(1,16)]\n",
    "test = [current_seq[i] for i in range(17,21)]\n",
    "\n",
    "train_target = [targets[i] for i in range(1,16)]\n",
    "test_target = [targets[i] for i in range(17,21)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nyyQSB2tlqPN"
   },
   "outputs": [],
   "source": [
    "train = np.array(train)\n",
    "test = np.array(test)\n",
    "\n",
    "train_target = np.array(train_target)\n",
    "train_target = (train_target+1)/2\n",
    "\n",
    "test_target = np.array(test_target)\n",
    "test_target = (test_target+1)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pBHTw64FluBQ"
   },
   "outputs": [],
   "source": [
    "#create an LSTM model having 512 units. It is a binary problem so you can use a dense layer with value 1 and activation sigmoid\n",
    "model = Sequential()\n",
    "model.add####\n",
    "model.add####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9-z4GdObmDBk"
   },
   "outputs": [],
   "source": [
    "#now you need to actually define the training process for the LSTM by adding optimiser (use ADAM or any other you want) and also play with different values for learning rate\n",
    "#create a check point so that you can get an outcome for each epoch\n",
    "model.compile (#binary cross entropy, optimiser, metrics=['accuracy'])\n",
    "model.fit(train, train_target, epochs=200, batch_size=32, callbacks=[chk], validation_data=(test,test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DmxGObnBm0kc"
   },
   "outputs": [],
   "source": [
    "#load the model created in order to estimate the accuracy on the training set\n",
    "#use the model.predict_classes to get the dataset you need to make the predictions and then compare the test_predicted values against the test_target one to get the final accuracy score\n",
    "\n",
    "\n",
    "\n",
    "##end of exercise###"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Untitled4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
